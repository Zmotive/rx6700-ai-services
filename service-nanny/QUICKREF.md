# Service Nanny - Visual Quick Reference

## ğŸ¯ What is Service Nanny?

```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   "I need to start a GPU service"   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      Service Nanny (Port 8080)      â”‚
         â”‚                                      â”‚
         â”‚  âœ“ Auto-discovers services          â”‚
         â”‚  âœ“ Enforces GPU one-of rule         â”‚
         â”‚  âœ“ Monitors health                  â”‚
         â”‚  âœ“ Manages lifecycle                â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“              â†“              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Stable â”‚    â”‚Service â”‚    â”‚Service â”‚
    â”‚   SD   â”‚    â”‚   2    â”‚    â”‚   3    â”‚
    â”‚  API   â”‚    â”‚        â”‚    â”‚        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start (3 Commands)

```bash
# 1. Start Service Nanny
cd service-nanny && ./start.sh

# 2. Start a service
curl -X POST http://localhost:8080/services/minimal-sd-api/start

# 3. Check it's running
curl http://localhost:8000/health
```

## ğŸ“‹ Adding a New Service (5 Steps)

```bash
# Step 1: Copy template
cp -r _template my-awesome-service

# Step 2: Edit service.yaml
cd my-awesome-service
vim service.yaml
# Change: name, description, ports, gpu_required

# Step 3: Edit docker-compose.yml  
vim docker-compose.yml
# Match ports to service.yaml

# Step 4: Test it works
docker compose up -d
curl http://localhost:8001/health  # Your port
docker compose down

# Step 5: Register with Service Nanny
curl -X POST http://localhost:8080/rediscover
curl http://localhost:8080/services | jq
```

## ğŸ® GPU Arbitration Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scenario: Two GPU services                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Start Service A (GPU)
         â†“
  âœ… Success - GPU free
         â†“
  Service A running
         â†“
  Start Service B (GPU)
         â†“
  âŒ 409 Conflict!
  "Service A is using GPU"
         â†“
  Start Service B (force=true)
         â†“
  ğŸ›‘ Stops Service A
         â†“
  ğŸš€ Starts Service B
         â†“
  âœ… Success
```

## ğŸ“Š API Cheat Sheet

| Want to... | Command |
|------------|---------|
| List all services | `curl http://localhost:8080/services \| jq` |
| Start a service | `curl -X POST http://localhost:8080/services/NAME/start` |
| Force start GPU service | `curl -X POST http://localhost:8080/services/NAME/start -d '{"force":true}'` |
| Stop a service | `curl -X POST http://localhost:8080/services/NAME/stop` |
| Check if healthy | `curl http://localhost:8080/services/NAME/status \| jq .is_healthy` |
| Get logs | `curl http://localhost:8080/services/NAME/logs?tail=50` |
| Rediscover services | `curl -X POST http://localhost:8080/rediscover` |

## ğŸ—‚ï¸ File Structure at a Glance

```
services/
â”‚
â”œâ”€â”€ ğŸ”§ service-nanny/          â† The orchestrator
â”‚   â”œâ”€â”€ service_nanny.py       â† Main app (350 lines)
â”‚   â”œâ”€â”€ docker-compose.yml     â† Runs on port 8080
â”‚   â”œâ”€â”€ start.sh               â† Quick start
â”‚   â”œâ”€â”€ test_api.sh            â† Test the API
â”‚   â”œâ”€â”€ README.md              â† Full API docs
â”‚   â”œâ”€â”€ ARCHITECTURE.md        â† Design details
â”‚   â””â”€â”€ IMPLEMENTATION.md      â† This implementation
â”‚
â”œâ”€â”€ ğŸ“‹ _template/              â† Copy-paste this!
â”‚   â”œâ”€â”€ service.yaml           â† Manifest for Service Nanny
â”‚   â”œâ”€â”€ docker-compose.yml     â† Container config
â”‚   â”œâ”€â”€ app.py                 â† FastAPI starter
â”‚   â”œâ”€â”€ SETUP.md               â† Step-by-step guide
â”‚   â””â”€â”€ README.md              â† Template docs
â”‚
â””â”€â”€ ğŸ¨ minimal-sd-api/         â† Example service
    â”œâ”€â”€ service.yaml           â† âœ¨ NEW - Nanny compatible
    â””â”€â”€ ...                    â† Existing files
```

## ğŸ”„ Typical Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Developer wants to add image upscaling API   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Copy template â†’ upscale-api/              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Edit service.yaml:                        â”‚
â”‚    name: upscale-api                         â”‚
â”‚    gpu_required: true                        â”‚
â”‚    ports: ["8001:8000"]                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Implement app.py logic                    â”‚
â”‚    - Load upscaling model                    â”‚
â”‚    - POST /upscale endpoint                  â”‚
â”‚    - Keep GET /health                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Test locally                              â”‚
â”‚    docker compose up -d                      â”‚
â”‚    curl http://localhost:8001/health         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Register with Service Nanny               â”‚
â”‚    curl -X POST .../rediscover               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… Done! Now manageable via Service Nanny    â”‚
â”‚                                               â”‚
â”‚ Start: POST /services/upscale-api/start      â”‚
â”‚ (Auto stops minimal-sd-api if running)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Port Allocation Guide

```
Port Range    Purpose              Currently Used
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
8000          GPU Service #1       minimal-sd-api
8001-8009     More GPU services    (available)
8010-8079     CPU services         (available)
8080          Service Nanny        RESERVED
8081-8099     (reserved)           (future use)
9000+         MCP servers          (future)
```

## ğŸ” Security Levels

```
Current (Development):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ No auth - Trusted users only   â”‚
â”‚ Docker socket access           â”‚
â”‚ localhost only                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Future (Production):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API key authentication         â”‚
â”‚ Role-based access control      â”‚
â”‚ Rate limiting                  â”‚
â”‚ HTTPS only                     â”‚
â”‚ Behind reverse proxy           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Learning Path

```
Beginner:
â”œâ”€ Read: main README.md
â”œâ”€ Start: ./start.sh
â””â”€ Try: curl commands from cheat sheet

Intermediate:
â”œâ”€ Copy template
â”œâ”€ Create simple CPU service
â”œâ”€ Test with Service Nanny
â””â”€ Read: ARCHITECTURE.md

Advanced:
â”œâ”€ Create GPU service
â”œâ”€ Understand GPU arbitration
â”œâ”€ Read: service_nanny.py source
â””â”€ Plan: MCP integration

Expert:
â”œâ”€ Contribute to Service Nanny
â”œâ”€ Add new features (auth, metrics)
â”œâ”€ Implement MCP protocol
â””â”€ Deploy to production
```

## ğŸ› Troubleshooting Quick Reference

| Problem | Solution |
|---------|----------|
| Service Nanny won't start | `docker compose logs` |
| Service not discovered | Check `service.yaml` exists |
| Can't start GPU service | Another GPU service running? |
| Health check fails | Check service's `/health` endpoint |
| Port conflict | Update `service.yaml` and `docker-compose.yml` |
| Docker permission denied | Add user to `docker` group |

## ğŸ‰ Success Indicators

âœ… You know it's working when:
- `curl http://localhost:8080/health` returns 200
- `curl http://localhost:8080/services` lists your services
- Starting a GPU service auto-stops another GPU service
- `/services/NAME/status` shows `is_healthy: true`
- New services appear after `POST /rediscover`

## ğŸš¦ Next Steps

1. âœ… **You are here** - Service Nanny is built and documented
2. â­ï¸ **Test it** - Run `./start.sh` and try the API
3. â­ï¸ **Add a service** - Use the template to create something new
4. â­ï¸ **MCP integration** - Make Service Nanny an MCP server
5. â­ï¸ **Scale up** - Add authentication, metrics, HA

---

**ğŸ¯ Remember**: The whole point is to make it *easy* to:
- Add new AI services (copy template)
- Start/stop them (one API call)
- Never worry about GPU conflicts (handled automatically)
- Eventually control everything via AI (MCP layer)
